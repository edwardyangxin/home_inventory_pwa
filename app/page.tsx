"use client";

import { useEffect, useState, useRef } from "react";
import { Mic, Square } from "lucide-react";

export default function Home() {
  const [isRecording, setIsRecording] = useState(false);
  const [transcript, setTranscript] = useState("");
  const [status, setStatus] = useState("å‡†å¤‡å°±ç»ª");
  const [isProcessing, setIsProcessing] = useState(false);
  const [apiResponse, setApiResponse] = useState("");
  const [error, setError] = useState<string | null>(null);

  const recognitionRef = useRef<any>(null);
  const timeoutRef = useRef<NodeJS.Timeout | null>(null);
  const transcriptRef = useRef(""); // To access latest transcript in callbacks

  useEffect(() => {
    if (typeof window !== "undefined") {
      const SpeechRecognition =
        (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;

      if (!SpeechRecognition) {
        setError("å½“å‰æµè§ˆå™¨ä¸æ”¯æŒ Web Speech API");
        return;
      }

      const recognition = new SpeechRecognition();
      recognition.lang = "zh-CN";
      recognition.continuous = true;
      recognition.interimResults = true;
      recognitionRef.current = recognition;

      recognition.onstart = () => {
        setIsRecording(true);
        setStatus("æ­£åœ¨å½•éŸ³... (30ç§’åè‡ªåŠ¨ç»“æŸ)");
        setError(null);
        setApiResponse("");
        transcriptRef.current = ""; 
        setTranscript("");

        // 30s timeout
        if (timeoutRef.current) clearTimeout(timeoutRef.current);
        timeoutRef.current = setTimeout(() => {
          stopRecording("è¶…æ—¶");
        }, 30000);
      };

      recognition.onend = () => {
        setIsRecording(false);
        if (timeoutRef.current) clearTimeout(timeoutRef.current);
        
        // Slight delay to ensure all state updates are processed? 
        // No, standard JS flow.
        const finalText = transcriptRef.current;
        
        // Only process if we have text and weren't already processing (avoid double submit if logic overlaps)
        // But onend is the definitive end.
        if (finalText && finalText.trim().length > 0) {
             processText(finalText);
        } else {
             setStatus("å½•éŸ³ç»“æŸ (æ— å†…å®¹)");
        }
      };

      recognition.onerror = (event: any) => {
        console.error("Speech Error:", event.error);
        if (event.error === 'no-speech') {
            setStatus("æœªæ£€æµ‹åˆ°è¯­éŸ³");
        } else {
            setError(`å‘ç”Ÿé”™è¯¯: ${event.error}`);
        }
      };

      recognition.onresult = (event: any) => {
        const currentFullTranscript = Array.from(event.results)
          .map((res: any) => res[0].transcript)
          .join("");

        setTranscript(currentFullTranscript);
        transcriptRef.current = currentFullTranscript;

        // Check for "over"
        if (currentFullTranscript.toLowerCase().includes("over")) {
          // Trigger stop
          if (recognitionRef.current) {
              recognitionRef.current.stop();
          }
          setStatus("å·²åœæ­¢ (æ£€æµ‹åˆ° 'over')");
        }
      };
    }
    
    return () => {
        if (timeoutRef.current) clearTimeout(timeoutRef.current);
        if (recognitionRef.current) recognitionRef.current.stop();
    }
  }, []);

  const startRecording = () => {
    setTranscript("");
    setApiResponse("");
    setError(null);
    try {
        recognitionRef.current?.start();
    } catch (e) {
        console.error(e);
        setError("æ— æ³•å¯åŠ¨å½•éŸ³ (å¯èƒ½æ­£åœ¨è¿›è¡Œä¸­)");
    }
  };

  const stopRecording = (reason?: string) => {
    if (recognitionRef.current) {
        recognitionRef.current.stop();
    }
    if (reason) setStatus(`å·²åœæ­¢ (${reason})`);
  };

  const mockPostToAPI = (text: string): Promise<string> => {
    return new Promise((resolve) => {
      setTimeout(() => {
        resolve(`æˆåŠŸæ¥æ”¶æ–‡æœ¬ï¼Œå­—ç¬¦é•¿åº¦: ${text.length}`);
      }, 1500);
    });
  };

  const processText = async (text: string) => {
      setStatus("æ­£åœ¨ä¸Šä¼ åˆ° API...");
      setIsProcessing(true);
      try {
          const response = await mockPostToAPI(text);
          setApiResponse(response);
          setStatus("å¤„ç†å®Œæˆ");
      } catch (e) {
          setStatus("ä¸Šä¼ å¤±è´¥");
          console.error(e);
      } finally {
          setIsProcessing(false);
      }
  };

  return (
    <div className="flex flex-col items-center min-h-screen p-8 pb-20 gap-8 sm:p-20 font-[family-name:var(--font-geist-sans)] max-w-md mx-auto">
      <header className="w-full text-center space-y-2">
        <h1 className="text-2xl font-bold">ğŸ™ è¯­éŸ³åŠ©æ‰‹</h1>
        <p className="text-sm text-gray-500">æœ¬åœ° STT + Mock API (PWA)</p>
      </header>

      <main className="flex-1 flex flex-col w-full gap-6">
        {/* Status Display */}
        <div className={`text-center py-2 px-4 rounded-full text-sm font-medium ${
            isRecording ? "bg-red-100 text-red-600 animate-pulse" : 
            isProcessing ? "bg-blue-100 text-blue-600" : "bg-gray-100 text-gray-600"
        }`}>
            {status}
        </div>

        {/* Transcript Area */}
        <div className="flex-1 border border-gray-200 rounded-xl p-4 bg-gray-50 min-h-[200px] overflow-y-auto shadow-inner">
            {transcript ? (
                <p className="text-lg text-gray-800 whitespace-pre-wrap">{transcript}</p>
            ) : (
                <p className="text-gray-400 italic">ç‚¹å‡»å¼€å§‹è¯´è¯...</p>
            )}
        </div>
        
        {/* API Response Area */}
        {apiResponse && (
            <div className="bg-green-50 border border-green-200 rounded-lg p-4 animate-in fade-in slide-in-from-bottom-2">
                <h3 className="text-xs font-bold text-green-700 uppercase tracking-wider mb-1">API å“åº”</h3>
                <p className="text-green-800">{apiResponse}</p>
            </div>
        )}

        {/* Error Display */}
        {error && (
             <div className="bg-red-50 border border-red-200 rounded-lg p-3 text-red-600 text-sm">
                {error}
             </div>
        )}

        {/* Controls */}
        <div className="flex justify-center gap-4 mt-auto">
            {!isRecording ? (
                <button 
                    onClick={startRecording}
                    disabled={isProcessing}
                    className="flex items-center gap-2 bg-black text-white px-6 py-3 rounded-full hover:bg-gray-800 active:scale-95 transition-all disabled:opacity-50 disabled:cursor-not-allowed shadow-lg"
                >
                    <Mic className="w-5 h-5" />
                    å¼€å§‹å½•éŸ³
                </button>
            ) : (
                <button 
                    onClick={() => stopRecording("æ‰‹åŠ¨åœæ­¢")}
                    className="flex items-center gap-2 bg-red-600 text-white px-6 py-3 rounded-full hover:bg-red-700 active:scale-95 transition-all shadow-lg animate-pulse"
                >
                    <Square className="w-5 h-5 fill-current" />
                    ç»“æŸå½•éŸ³
                </button>
            )}
        </div>
      </main>
      
      <footer className="text-xs text-gray-400 text-center">
        æ”¯æŒ: "Over" è‡ªåŠ¨ç»“æŸ, 30s è¶…æ—¶
      </footer>
    </div>
  );
}